{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and init\n",
    "from copy import deepcopy\n",
    "# import logging\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "from pprint import PrettyPrinter\n",
    "import xml.etree.ElementTree as ET\n",
    "import xmltodict\n",
    "\n",
    "from resources.parser import WeaponMetaParser, PickupsMetaParser\n",
    "from resources.conversion import DLC_TO_DEVICENAME\n",
    "\n",
    "ROOT_PATH = './vanilla'\n",
    "PATH_OUTPUTS = './outputs'\n",
    "DELETE_TOKEN = '!DELETE'\n",
    "\n",
    "pp = PrettyPrinter(indent=1, compact=True, sort_dicts=False)\n",
    "def pprint(obj):\n",
    "    return pp.pprint(obj)\n",
    "\n",
    "for f in ['supplementary-docs', 'merged']:\n",
    "    if not os.path.isdir(f'{PATH_OUTPUTS}/{f}'):\n",
    "        os.makedirs(f'{PATH_OUTPUTS}/{f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crawl list of all DLCs from latest dlclist.xml.\n",
    "# Devlog: 2024-01-16, GTA V 1.70, have scanned up to patch2024_02\n",
    "if True:\n",
    "    f = f'{ROOT_PATH}/update/update.rpf/common/data/dlclist.xml'\n",
    "    dlcs_xml = ET.parse(source=f).getroot()\n",
    "    dlcs = {\n",
    "        'base': {\n",
    "            'base': {'path': f'update/update.rpf'},\n",
    "        }\n",
    "    }\n",
    "    for i in dlcs_xml.find('Paths'):\n",
    "        dlc_archive, dlc_subpath = i.text.split(sep=':')\n",
    "        \n",
    "        if dlc_subpath[-1] == '/':\n",
    "            dlc_subpath = dlc_subpath[0:-1]\n",
    "        dlc_name = dlc_subpath.split(sep='/')[-1].lower()\n",
    "\n",
    "        if dlc_archive == 'platform':\n",
    "            dlc_path = f'x64w.rpf/dlcpacks/{dlc_name}/dlc.rpf'\n",
    "        elif dlc_archive == 'dlcpacks':\n",
    "            dlc_path = f'update/x64/dlcpacks/{dlc_name}/dlc.rpf'\n",
    "        else:\n",
    "            raise ValueError(f'Unknown archive type.')\n",
    "        \n",
    "        dlcs[dlc_name] = {'base': {'path': dlc_path}}\n",
    "    print(f)\n",
    "\n",
    "# Crawl list of all DLC patches from latest extratitleupdatedata.meta.\n",
    "if True:\n",
    "    f = f'{ROOT_PATH}/update/update.rpf/common/data/extratitleupdatedata.meta'\n",
    "    dlcpatch_xml = ET.parse(source=f).getroot()\n",
    "    dlcpatch_xmldict = xmltodict.parse(ET.tostring(dlcpatch_xml))\n",
    "    prefix = 'update:/dlc_patch/'\n",
    "    for i in dlcpatch_xmldict['SExtraTitleUpdateData']['Mounts']['Item']:\n",
    "        assert i['path'].startswith(prefix) and i['path'].endswith('/')\n",
    "        dlc_name = i['path'][len(prefix):-1].lower()\n",
    "        dlcs[dlc_name].update({'patch': {'path': f'update/update.rpf/dlc_patch/{dlc_name}'}})\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan for all content.xml, weapon<...>.meta, pickups.meta files in all dlc archives.\n",
    "for dlc in dlcs.keys():\n",
    "    for installment in ['base', 'patch']:\n",
    "        if (installment == 'base') or ('patch' in dlcs[dlc].keys()):\n",
    "            dlcs[dlc][installment].update({'weapons': [], 'pickups': [], 'content': []})\n",
    "            # Scan content.xml\n",
    "            if os.path.isfile(f'{ROOT_PATH}/{dlcs[dlc][installment]['path']}/content.xml'):\n",
    "                dlcs[dlc][installment]['content'] = [f\"{dlcs[dlc][installment]['path']}/content.xml\"]\n",
    "            # Scan weapon-.meta | Will need better filtering when working with more types of config\n",
    "            path_folder = f\"{ROOT_PATH}/{dlcs[dlc][installment]['path']}/common/data/ai\"\n",
    "            if os.path.isdir(path_folder):\n",
    "                for f in os.listdir(path_folder):\n",
    "                    if ('weapon' in f) and (f.endswith('.meta')):\n",
    "                        dlcs[dlc][installment]['weapons'].append(f'{dlcs[dlc][installment]['path']}/common/data/ai/{f}')\n",
    "            # Scan pickups.meta\n",
    "            if os.path.isfile(f'{ROOT_PATH}/{dlcs[dlc][installment]['path']}/common/data/pickups.meta'):\n",
    "                dlcs[dlc][installment]['pickups'] = [f\"{dlcs[dlc][installment]['path']}/common/data/pickups.meta\"]\n",
    "\n",
    "def print_dlcs(dlcs):\n",
    "    bool_to_int = {True: 1, False: 0}\n",
    "    for dlc, dlc_content in dlcs.items():\n",
    "        print(f\"{dlc.ljust(17)}    base     pickups: {bool_to_int[dlc_content['base']['pickups']['avail']]}    weapon: {dlc_content['base']['weapons']['files']}\")\n",
    "        if dlcs[dlc].get('patch'):\n",
    "            print(f\"{dlc.ljust(17)}    patch    pickups: {bool_to_int[dlc_content['patch']['pickups']['avail']]}    weapon: {dlc_content['patch']['weapons']['files']}\")\n",
    "# print_dlcs(dlcs)\n",
    "\n",
    "# Export list of dlcs\n",
    "with open(f'{PATH_OUTPUTS}/supplementary-docs/dlcs.yaml', 'w') as f:\n",
    "    yaml.dump(data=dlcs, stream=f, indent=2, sort_keys=False)\n",
    "print(f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge weapons data from all vanilla files\n",
    "weaponmetaparser = WeaponMetaParser(template_source=f'{ROOT_PATH}/{dlcs['base']['base']['weapons'][0]}')\n",
    "for dlc in dlcs.keys():\n",
    "    for installment in ['base', 'patch']:\n",
    "        if (installment == 'base') or ('patch' in dlcs[dlc].keys()):\n",
    "            for f in dlcs[dlc][installment]['weapons']:\n",
    "                new_weaponmeta = weaponmetaparser.parse_xmltodict(source=f'{ROOT_PATH}/{f}')\n",
    "                weaponmetaparser.update(new=new_weaponmeta, metadata={'dlc': dlc, 'installment': installment, 'path': f})\n",
    "weaponmetaparser.template['CWeaponInfoBlob']['Name'] = 'Merged 1.70'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export merged weapons info to .meta\n",
    "if True:\n",
    "    f = f'{PATH_OUTPUTS}/merged/update/update.rpf/common/data/ai/weapons.meta'\n",
    "    if not os.path.isdir(os.path.dirname(f)):\n",
    "        os.makedirs(os.path.dirname(f))\n",
    "    weapons_merged_meta = deepcopy(weaponmetaparser.template)\n",
    "    weapons_merged_meta_xml = ET.ElementTree(element=ET.fromstring(text=xmltodict.unparse(\n",
    "        input_dict=weapons_merged_meta,\n",
    "        encoding='utf-8',\n",
    "        pretty=True,\n",
    "        indent=2,\n",
    "    )))\n",
    "    weapons_merged_meta_xml.write(\n",
    "        file_or_filename=f,\n",
    "        encoding=\"utf-8\",\n",
    "        xml_declaration=True,\n",
    "    )\n",
    "    print(f)\n",
    "\n",
    "# Export logs from callbacks (list of weapons and weapons by dlc)\n",
    "with open(f'{PATH_OUTPUTS}/supplementary-docs/ammos_by_dlc.yaml', 'w') as f:\n",
    "    yaml.dump(data=weaponmetaparser.structure['Infos'][0]['callbacks'][0].data, stream=f, indent=2, sort_keys=False)\n",
    "print(f.name)\n",
    "\n",
    "with open(f'{PATH_OUTPUTS}/supplementary-docs/weapons_by_dlc.yaml', 'w') as f:\n",
    "    yaml.dump(data=weaponmetaparser.structure['Infos'][1]['callbacks'][0].data, stream=f, indent=2, sort_keys=False)\n",
    "print(f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge pickups data from all vanilla files\n",
    "pickupsmetaparser = PickupsMetaParser(template_source=f'{ROOT_PATH}/{dlcs['base']['base']['pickups'][0]}')\n",
    "for dlc in dlcs.keys():\n",
    "    for installment in ['base', 'patch']:\n",
    "        if (installment == 'base') or ('patch' in dlcs[dlc].keys()):\n",
    "            for f in dlcs[dlc][installment]['pickups']:\n",
    "                new_pickups = pickupsmetaparser.parse_xmltodict(source=f'{ROOT_PATH}/{f}')\n",
    "                pickupsmetaparser.update(new=new_pickups, metadata={'dlc': dlc, 'installment': installment, 'path': f})\n",
    "\n",
    "# Export merged pickups info to .meta\n",
    "if True:\n",
    "    f = f'{PATH_OUTPUTS}/merged/update/update.rpf/common/data/pickups.meta'\n",
    "    pickups_merged_meta = deepcopy(pickupsmetaparser.template)\n",
    "    pickups_merged_meta_xml = ET.ElementTree(element=ET.fromstring(text=xmltodict.unparse(\n",
    "        input_dict=pickups_merged_meta,\n",
    "        encoding='utf-8',\n",
    "        pretty=True,\n",
    "        indent=2,\n",
    "    )))\n",
    "    pickups_merged_meta_xml.write(\n",
    "        file_or_filename=f,\n",
    "        encoding=\"utf-8\",\n",
    "        xml_declaration=True,\n",
    "    )\n",
    "    print(f)\n",
    "\n",
    "    # Export logs from callbacks (list of weapons and weapons by dlc)\n",
    "    with open(f'{PATH_OUTPUTS}/supplementary-docs/pickups_by_dlc.yaml', 'w') as f:\n",
    "        yaml.dump(data=pickupsmetaparser.structure['pickupData']['callbacks'][0].data, stream=f, indent=2, sort_keys=False)\n",
    "    print(f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert content.xml to deactivate old weapon-.meta and pickups.meta\n",
    "for dlc in dlcs.keys():\n",
    "    if (dlc == 'base'):\n",
    "        continue\n",
    "\n",
    "    # Compose list of file to unload | Skip if no need to unload\n",
    "    blacklist = []\n",
    "    for installment in ['base', 'patch']:\n",
    "        if (installment == 'patch') and (dlcs[dlc].get('patch') is None):\n",
    "            continue\n",
    "        for w in dlcs[dlc][installment]['weapons']:\n",
    "            w_name = f'common/data/ai/{w.split(sep='common/data/ai/')[-1]}'\n",
    "            if w_name not in blacklist:\n",
    "                blacklist.append(w_name)\n",
    "        for p in dlcs[dlc][installment]['pickups']:\n",
    "            p_name = f'common/data/{p.split(sep='common/data/')[-1]}'\n",
    "            if p_name not in blacklist:\n",
    "                blacklist.append(p_name)\n",
    "\n",
    "    if blacklist == []:\n",
    "        continue\n",
    "    \n",
    "    for installment in ['base', 'patch']:\n",
    "        if (installment == 'patch') and (dlcs[dlc].get('patch') is None):\n",
    "            continue\n",
    "        \n",
    "        if len(dlcs[dlc][installment]['content']) > 0:\n",
    "            content_xml = ET.parse(f'{ROOT_PATH}/{dlcs[dlc][installment][\"content\"][0]}').getroot()\n",
    "            for ccs in content_xml.find('contentChangeSets'):\n",
    "                if 'AUTOGEN' not in ccs.find('changeSetName').text:\n",
    "                    continue\n",
    "                \n",
    "                files_to_enable = ccs.find('filesToEnable')\n",
    "                for fe in list(files_to_enable):\n",
    "                    flag_unload = [fu in fe.text.lower() for fu in blacklist]\n",
    "                    if any(flag_unload):\n",
    "                        files_to_enable.remove(fe)\n",
    "                        print(f'{dlc}-{installment}: {fe.text} unloaded')\n",
    "        \n",
    "        # Export content.xml to dlc_patch\n",
    "        # ! Both installment 'base' and 'patch' are process, but then 'patch'\n",
    "        #   can overwrite 'base'\n",
    "        f = f'{PATH_OUTPUTS}/merged/update/update.rpf/dlc_patch/{dlc}/content.xml'\n",
    "        if not os.path.isdir(os.path.dirname(f)):\n",
    "            os.makedirs(os.path.dirname(f))\n",
    "        ET.ElementTree(element=content_xml).write(\n",
    "            file_or_filename=f,\n",
    "            encoding=\"utf-8\",\n",
    "            xml_declaration=True,\n",
    "        )\n",
    "        print(f'{dlc}-{installment}: {f} saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter content.xml files per dlc_patch for uninstallation\n",
    "flag_backup_content = {\n",
    "    'to-delete': [],\n",
    "    'to-patch': [],\n",
    "}\n",
    "\n",
    "for dlc in dlcs.keys():\n",
    "    if (dlc == 'base'):\n",
    "        continue\n",
    "    \n",
    "    if len(dlcs[dlc]['base']['content']) > 0:\n",
    "        flag_backup_content['to-delete'].append(dlc)\n",
    "        \n",
    "        if (dlcs[dlc].get('patch') is not None):\n",
    "            if len(dlcs[dlc]['patch']['content']) > 0:\n",
    "                flag_backup_content['to-delete'].remove(dlc)\n",
    "                flag_backup_content['to-patch'].append(dlc)\n",
    "\n",
    "flag_backup_content['to-delete'].sort()\n",
    "flag_backup_content['to-patch'].sort()\n",
    "\n",
    "# Export logs from callbacks (list of weapons and weapons by dlc)\n",
    "with open(f'{PATH_OUTPUTS}/uninstall-content-dlcpatch.yaml', 'w') as f:\n",
    "    yaml.dump(data=flag_backup_content, stream=f, indent=2, sort_keys=False)\n",
    "print(f.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weapon-merger",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
